# DeepSearch Agent Configuration
# This file demonstrates the agent setup for the DeepSearch research agent
# that combines web search (mcp-tavily) and web scraping (mcp-spider)

server:
  host: "127.0.0.1"
  port: 8080
  documentation_url: "https://github.com/distrihub/distri"
  preferred_transport: "JSONRPC"

  # A2A capabilities
  capabilities:
    streaming: true
    push_notifications: true
    state_transition_history: true
    extensions: []

  # Default input/output modes
  default_input_modes:
    - "text/plain"
    - "text/markdown"

  default_output_modes:
    - "text/plain"
    - "text/markdown"

  # Security configuration (optional)
  security_schemes: {}
  security: []

# Agent definitions
agents:
  - name: "deep_search"
    description: "An intelligent research agent that combines web search and scraping for comprehensive answers"
    model: "gpt-4o-mini"
    system_prompt: |
      You are DeepSearch, an intelligent research agent. When given a query, you should:
      1. First search for relevant information using web search
      2. Then scrape detailed content from the most relevant sources
      3. Synthesize the information to provide comprehensive, well-sourced answers
      
      Focus on accuracy and providing multiple perspectives when relevant.
      Always cite your sources and provide structured, easy-to-read responses.
    icon_url: "https://example.com/deep-search-icon.png"
    mcp_servers:
      - name: "mcp-tavily"
        filter: "all"
        type: "tool"
      - name: "mcp-spider" 
        filter: "all"
        type: "tool"
    parameters:
      search_depth: "comprehensive"
      max_sources: 5
      scrape_timeout: 30
    max_iterations: 5

# MCP server configurations
mcp_servers:
  - name: "mcp-tavily"
    config:
      transport:
        type: "stdio"
        command: "mcp-tavily"
        args: []
        env_vars:
          TAVILY_API_KEY: "${TAVILY_API_KEY}"
      tools:
        - name: "search"
          description: "Search the web using Tavily API"
        - name: "search_news"
          description: "Search for recent news using Tavily API"
        - name: "get_extract"
          description: "Extract content from a specific URL"

  - name: "mcp-spider"
    config:
      transport:
        type: "stdio"
        command: "mcp-spider"
        args: ["--stealth-mode"]
        env_vars: {}
      tools:
        - name: "scrape"
          description: "Scrape content from a URL using spider-rs"

# Logging configuration
logging:
  level: "info"
  verbose: true