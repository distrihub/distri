import { createOpenAI } from '@ai-sdk/openai';
import { streamText, convertToCoreMessages } from 'ai';
import { NextRequest, NextResponse } from 'next/server';

// Allow streaming responses up to 30 seconds
export const maxDuration = 30;

// Configure OpenAI client with LangDB gateway if available
const openaiClient = createOpenAI({
  baseURL: process.env.LANGDB_API_KEY 
    ? 'https://api.us-east-1.langdb.ai/v1' 
    : undefined,
  apiKey: process.env.LANGDB_API_KEY || process.env.OPENAI_API_KEY,
  headers: process.env.LANGDB_PROJECT_ID ? {
    'X-Project-Id': process.env.LANGDB_PROJECT_ID,
  } : undefined,
});

interface DistriAgent {
  id: string;
  name: string;
  description: string;
  capabilities: Record<string, unknown>;
}

// Function to get available agents from distri-server
async function getDistriAgents(): Promise<DistriAgent[]> {
  try {
    const response = await fetch(`${process.env.DISTRI_A2A_ENDPOINT}/agents`, {
      headers: {
        'Content-Type': 'application/json',
      },
    });
    
    if (!response.ok) {
      console.error('Failed to fetch agents:', response.statusText);
      return [];
    }
    
    return await response.json();
  } catch (error) {
    console.error('Error fetching agents:', error);
    return [];
  }
}

// Function to send message to distri-server agent
async function sendToDistriAgent(agentId: string, message: string): Promise<string> {
  try {
    const response = await fetch(`${process.env.DISTRI_A2A_ENDPOINT}/agents/${agentId}`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
      },
      body: JSON.stringify({
        jsonrpc: '2.0',
        id: Math.random().toString(36).substring(7),
        method: 'message/send',
        params: {
          message: {
            content: [
              {
                type: 'text',
                text: message,
              },
            ],
          },
        },
      }),
    });

    if (!response.ok) {
      throw new Error(`Distri server error: ${response.statusText}`);
    }

    const result = await response.json();
    return result.result?.content?.[0]?.text || 'No response from agent';
  } catch (error) {
    console.error('Error communicating with distri agent:', error);
    throw error;
  }
}

export async function POST(req: NextRequest) {
  try {
    const { messages, useDistriAgent, agentId } = await req.json();
    
    // Convert messages to the core message format
    const coreMessages = convertToCoreMessages(messages);
    
    // Get the latest user message
    const latestMessage = coreMessages[coreMessages.length - 1];
    const userMessage = latestMessage?.content?.toString() || '';

    // If using distri agent, route through distri-server
    if (useDistriAgent && agentId && userMessage) {
      try {
        const agentResponse = await sendToDistriAgent(agentId, userMessage);
        
        // Return the agent response as a stream
        const result = await streamText({
          model: openaiClient('gpt-4o-mini'),
          messages: [
            {
              role: 'system',
              content: `You are a helpful AI assistant powered by the Distri system. The following response was generated by a specialized agent: "${agentResponse}". Present this information naturally and helpfully to the user.`
            },
            {
              role: 'user',
              content: userMessage
            }
          ],
          temperature: 0.7,
        });

        return result.toDataStreamResponse();
      } catch (error) {
        console.error('Distri agent error:', error);
        // Fall back to direct OpenAI if distri agent fails
      }
    }

    // Default: Use LangDB gateway (OpenAI through your existing langdb configuration)
    const result = await streamText({
      model: openaiClient('gpt-4o-mini'),
      messages: [
        {
          role: 'system',
          content: `You are a helpful AI assistant powered by LangDB and the Distri distributed AI system. You can help users with various tasks and connect them to specialized agents when needed.
          
Current capabilities:
- General conversation and assistance
- Integration with distributed AI agents
- Real-time streaming responses
- Dark/light mode UI support

Always be helpful, concise, and engaging. If a user asks about specialized tasks that might benefit from a specific agent, mention that they can enable "Agent Mode" to connect to specialized Distri agents.`
        },
        ...coreMessages,
      ],
      temperature: 0.7,
      maxTokens: 1000,
    });

    return result.toDataStreamResponse();
  } catch (error) {
    console.error('Chat API error:', error);
    return NextResponse.json(
      { error: 'Internal server error' },
      { status: 500 }
    );
  }
}

// GET endpoint to retrieve available agents
export async function GET() {
  try {
    const agents = await getDistriAgents();
    return NextResponse.json({ agents });
  } catch (error) {
    console.error('Error fetching agents:', error);
    return NextResponse.json(
      { error: 'Failed to fetch agents' },
      { status: 500 }
    );
  }
}