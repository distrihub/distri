name = "example-workspace"
version = "0.1.0"

# Copy this file to your workspace root and tweak values as needed.
# The server automatically reads distri.toml from the workspace directory.

[model_settings]
model = "gpt-4.1-mini"
temperature = 0.2
max_tokens = 4000
context_size = 32000

[model_settings.provider]
name = "openai"

[analysis_model_settings]
model = "gpt-4.1-mini"
temperature = 0.0
max_tokens = 2000
context_size = 32000

[analysis_model_settings.provider]
name = "openai"


# [model_settings.provider]
# name = "vllora"
# base_url = "http://localhost:1237/v1"

# [analysis_model_settings.provider]
# name = "vllora"
# base_url = "http://localhost:1237/v1"
